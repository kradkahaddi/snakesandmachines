{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e3c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code is adapted from d2l.ai - Chapter 5 with additions and other experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b837f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72da5aec",
   "metadata": {},
   "source": [
    "## Layers and Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b74c2d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2049,  0.1291, -0.2545, -0.1309, -0.3377,  0.1748,  0.1382, -0.0494,\n",
       "         -0.0386,  0.1386],\n",
       "        [ 0.3130,  0.1367, -0.3545,  0.0466, -0.2267,  0.1971,  0.1951, -0.0432,\n",
       "          0.0279,  0.2282]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd30b889",
   "metadata": {},
   "source": [
    "## Custom Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab74fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    # Declare a layer with model parameters. Here, we declare two fully\n",
    "    # connected layers\n",
    "    def __init__(self):\n",
    "        # Call the constructor of the `MLP` parent class `Module` to perform\n",
    "        # the necessary initialization. In this way, other function arguments\n",
    "        # can also be specified during class instantiation, such as the model\n",
    "        # parameters, `params` (to be described later)\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)  # Hidden layer\n",
    "        self.out = nn.Linear(256, 10)  # Output layer\n",
    "\n",
    "    # Define the forward propagation of the model, that is, how to return the\n",
    "    # required model output based on the input `X`\n",
    "    def forward(self, X):\n",
    "        # Note here we use the funtional version of ReLU defined in the\n",
    "        # nn.functional module.\n",
    "        return self.out(F.relu(self.hidden(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac86e2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0198, -0.1493, -0.0520, -0.0848, -0.3571,  0.0851,  0.0647,  0.0770,\n",
       "         -0.3174, -0.2176],\n",
       "        [ 0.1417, -0.2123,  0.0369, -0.1612, -0.3030,  0.1386,  0.1829,  0.0036,\n",
       "         -0.1788, -0.2200]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea8dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.apply(init_fn) #kaiming_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59347a79",
   "metadata": {},
   "source": [
    "## Custom Sequential Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66d0bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            # Here, `module` is an instance of a `Module` subclass. We save it\n",
    "            # in the member variable `_modules` of the `Module` class, and its\n",
    "            # type is OrderedDict\n",
    "            self._modules[str(idx)] = module\n",
    "\n",
    "    def forward(self, X):\n",
    "        # OrderedDict guarantees that members will be traversed in the order\n",
    "        # they were added\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d399ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0233,  0.0504, -0.1248, -0.1506,  0.0467,  0.0192,  0.2111,  0.0061,\n",
       "          0.3107, -0.0725],\n",
       "        [ 0.0296,  0.1258, -0.0918, -0.1302,  0.0314, -0.1343,  0.0989,  0.1752,\n",
       "          0.1854, -0.1540]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821fa058",
   "metadata": {},
   "source": [
    "## Tensor Ops in forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c4d0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Random weight parameters that will not compute gradients and\n",
    "        # therefore keep constant during training\n",
    "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "        self.linear2 = nn.Linear(20, 21)\n",
    "        self.linear3 = nn.Linear(21, 20)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X2 = X.clone()\n",
    "        X2 = self.linear2(X2)\n",
    "        X2 = self.linear3(X2)\n",
    "        X = self.linear(X)\n",
    "        # Use the created constant parameters, as well as the `relu` and `mm`\n",
    "        # functions\n",
    "        X += X2\n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
    "        # Reuse the fully-connected layer. This is equivalent to sharing\n",
    "        # parameters with two fully-connected layers\n",
    "        X = self.linear(X)\n",
    "        # Control flow\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "75ff908c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1283, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85acdc42",
   "metadata": {},
   "source": [
    "## Nested Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d39aa3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1106, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),\n",
    "                                 nn.Linear(64, 32), nn.ReLU())\n",
    "        self.linear = nn.Linear(32, 16)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "\n",
    "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
    "chimera(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a55067a",
   "metadata": {},
   "source": [
    "## Params management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7414f432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2727],\n",
       "        [-0.2193]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7342413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[ 0.0528,  0.4438, -0.3360, -0.4050],\n",
       "                      [-0.2925, -0.3386, -0.2287, -0.0947],\n",
       "                      [ 0.1488,  0.4780,  0.0384,  0.2653],\n",
       "                      [-0.1007,  0.0819,  0.4925,  0.4800],\n",
       "                      [ 0.4627,  0.2437,  0.4010, -0.0476],\n",
       "                      [-0.2228, -0.2406, -0.3776, -0.1833],\n",
       "                      [-0.2953, -0.3693,  0.3597,  0.3371],\n",
       "                      [ 0.2478,  0.2785, -0.1406,  0.0031]])),\n",
       "             ('0.bias',\n",
       "              tensor([ 0.4938, -0.3451, -0.3527,  0.2861, -0.4172, -0.2159,  0.2688, -0.0559])),\n",
       "             ('2.weight',\n",
       "              tensor([[ 0.0450,  0.0599, -0.2341, -0.2108, -0.1914, -0.0172, -0.3188,  0.1648]])),\n",
       "             ('2.bias', tensor([0.0291]))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d02edd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 0.0528,  0.4438, -0.3360, -0.4050],\n",
       "                      [-0.2925, -0.3386, -0.2287, -0.0947],\n",
       "                      [ 0.1488,  0.4780,  0.0384,  0.2653],\n",
       "                      [-0.1007,  0.0819,  0.4925,  0.4800],\n",
       "                      [ 0.4627,  0.2437,  0.4010, -0.0476],\n",
       "                      [-0.2228, -0.2406, -0.3776, -0.1833],\n",
       "                      [-0.2953, -0.3693,  0.3597,  0.3371],\n",
       "                      [ 0.2478,  0.2785, -0.1406,  0.0031]])),\n",
       "             ('bias',\n",
       "              tensor([ 0.4938, -0.3451, -0.3527,  0.2861, -0.4172, -0.2159,  0.2688, -0.0559]))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548767e",
   "metadata": {},
   "source": [
    "## Targeting Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09839949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4938, -0.3451, -0.3527,  0.2861, -0.4172, -0.2159,  0.2688, -0.0559])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aabdb8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.9000e+01,  9.9000e+01,  9.9000e+01,  9.9000e+01],\n",
       "        [ 9.9000e+01,  9.9000e+01,  9.9000e+01,  9.9000e+01],\n",
       "        [ 9.9000e+01,  9.9000e+01,  9.9000e+01,  9.9000e+01],\n",
       "        [ 9.9000e+01,  9.9000e+01,  9.9000e+01,  9.9000e+01],\n",
       "        [ 4.6275e-01,  2.4371e-01,  4.0105e-01, -4.7602e-02],\n",
       "        [-2.2279e-01, -2.4063e-01, -3.7756e-01, -1.8331e-01],\n",
       "        [-2.9535e-01, -3.6929e-01,  3.5972e-01,  3.3714e-01],\n",
       "        [ 2.4776e-01,  2.7851e-01, -1.4060e-01,  3.1351e-03]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data[:4,:4] = 99.\n",
    "\n",
    "net[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afad5a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0291])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['2.bias'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4225d81",
   "metadata": {},
   "source": [
    "## All params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31125242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2593dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## <named_parameters()>, children, parameters, modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e9aad07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
     ]
    }
   ],
   "source": [
    "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n",
    "print(*[(name, param.shape) for name, param in net.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77cab0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 9.9000e+01,  9.9000e+01,  9.9000e+01,  9.9000e+01],\n",
       "          [ 9.9000e+01,  9.9000e+01,  9.9000e+01,  9.9000e+01],\n",
       "          [ 9.9000e+01,  9.9000e+01,  9.9000e+01,  9.9000e+01],\n",
       "          [ 9.9000e+01,  9.9000e+01,  9.9000e+01,  9.9000e+01],\n",
       "          [ 4.6275e-01,  2.4371e-01,  4.0105e-01, -4.7602e-02],\n",
       "          [-2.2279e-01, -2.4063e-01, -3.7756e-01, -1.8331e-01],\n",
       "          [-2.9535e-01, -3.6929e-01,  3.5972e-01,  3.3714e-01],\n",
       "          [ 2.4776e-01,  2.7851e-01, -1.4060e-01,  3.1351e-03]],\n",
       "         requires_grad=True)),\n",
       " ('0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.4938, -0.3451, -0.3527,  0.2861, -0.4172, -0.2159,  0.2688, -0.0559],\n",
       "         requires_grad=True)),\n",
       " ('2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0450,  0.0599, -0.2341, -0.2108, -0.1914, -0.0172, -0.3188,  0.1648]],\n",
       "         requires_grad=True)),\n",
       " ('2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0291], requires_grad=True))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0588add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## <parameters()>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e36f9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 9.9000e+01,  9.9000e+01,  9.9000e+01,  9.9000e+01],\n",
       "         [ 9.9000e+01,  9.9000e+01,  9.9000e+01,  9.9000e+01],\n",
       "         [ 9.9000e+01,  9.9000e+01,  9.9000e+01,  9.9000e+01],\n",
       "         [ 9.9000e+01,  9.9000e+01,  9.9000e+01,  9.9000e+01],\n",
       "         [ 4.6275e-01,  2.4371e-01,  4.0105e-01, -4.7602e-02],\n",
       "         [-2.2279e-01, -2.4063e-01, -3.7756e-01, -1.8331e-01],\n",
       "         [-2.9535e-01, -3.6929e-01,  3.5972e-01,  3.3714e-01],\n",
       "         [ 2.4776e-01,  2.7851e-01, -1.4060e-01,  3.1351e-03]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.4938, -0.3451, -0.3527,  0.2861, -0.4172, -0.2159,  0.2688, -0.0559],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0450,  0.0599, -0.2341, -0.2108, -0.1914, -0.0172, -0.3188,  0.1648]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0291], requires_grad=True)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95b1320a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', Linear(in_features=4, out_features=8, bias=True)),\n",
       " ('1', ReLU()),\n",
       " ('2', Linear(in_features=8, out_features=1, bias=True))]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aecba28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=4, out_features=8, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=8, out_features=1, bias=True)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.children())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012fad07",
   "metadata": {},
   "source": [
    "## Collecting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0fd1a51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "357eb883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2556],\n",
       "        [-0.2556]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 4),\n",
    "                         nn.ReLU())\n",
    "\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        # Nested here\n",
    "        net.add_module(f'block {i}', block1())\n",
    "    return net\n",
    "\n",
    "def block3():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        net.add_module(f'block_2 {i}', block2())\n",
    "    return net\n",
    "\n",
    "rgnet2 = nn.Sequential(block3(), nn.Linear(4,1))\n",
    "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
    "rgnet(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d73b3a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block 0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rgnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a48ab33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (block 0): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (block 1): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (block 2): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (block 3): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
       "  (fc): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet.add_module('fc', nn.Linear(1,1, bias=True))\n",
    "rgnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71ec31c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.block 0.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1639,  0.2251, -0.4275, -0.4276],\n",
       "          [-0.1055,  0.1964, -0.2566, -0.3146],\n",
       "          [-0.0649,  0.1358, -0.2405, -0.4776],\n",
       "          [-0.2704, -0.0756, -0.1673,  0.4028],\n",
       "          [-0.1686,  0.3300,  0.0248,  0.0440],\n",
       "          [-0.0455, -0.0727,  0.1271,  0.0872],\n",
       "          [-0.3912, -0.1992,  0.0052, -0.0626],\n",
       "          [-0.1598,  0.0920, -0.2388, -0.4927]], requires_grad=True)),\n",
       " ('0.block 0.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.3822,  0.1829,  0.0156, -0.1684,  0.0761,  0.1758, -0.0640, -0.4413],\n",
       "         requires_grad=True)),\n",
       " ('0.block 0.2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 2.9448e-04, -1.2497e-01, -2.6117e-01,  3.0121e-01, -2.4586e-01,\n",
       "            1.1525e-01,  1.1274e-01, -2.8943e-01],\n",
       "          [ 6.0678e-05, -3.0486e-01, -1.8523e-01,  1.7244e-01, -8.3854e-02,\n",
       "           -2.0622e-01, -1.7788e-01,  1.3064e-01],\n",
       "          [ 6.0024e-02,  3.1581e-01,  2.8538e-02,  2.4565e-02, -3.3780e-01,\n",
       "           -3.0268e-01,  2.7581e-01, -3.2305e-01],\n",
       "          [ 3.1388e-01, -2.5387e-01,  1.0965e-01,  2.5348e-01, -3.2901e-01,\n",
       "           -3.3791e-01,  3.5155e-01, -3.3635e-01]], requires_grad=True)),\n",
       " ('0.block 0.2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.3401,  0.3132, -0.3024,  0.2860], requires_grad=True)),\n",
       " ('0.block 1.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1336, -0.1995,  0.2449,  0.4198],\n",
       "          [-0.0728, -0.4344, -0.3410, -0.4169],\n",
       "          [-0.3948,  0.3852,  0.0481, -0.1646],\n",
       "          [-0.3447,  0.0292, -0.0877,  0.2629],\n",
       "          [ 0.3083, -0.1924,  0.4442, -0.1529],\n",
       "          [-0.3885, -0.1417,  0.3478,  0.1737],\n",
       "          [-0.1381, -0.2959,  0.2470, -0.4145],\n",
       "          [-0.1498, -0.3662,  0.3438,  0.3000]], requires_grad=True)),\n",
       " ('0.block 1.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.3766, -0.0611, -0.4432, -0.4459, -0.0248, -0.1326, -0.4823, -0.4727],\n",
       "         requires_grad=True)),\n",
       " ('0.block 1.2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1238,  0.1168, -0.2286,  0.0250, -0.0698,  0.2412, -0.2949,  0.1938],\n",
       "          [ 0.1587, -0.1360,  0.1145, -0.2914,  0.0062, -0.2508,  0.0323,  0.0420],\n",
       "          [-0.1957,  0.1594, -0.2187,  0.3246,  0.0606, -0.3478, -0.0421,  0.0562],\n",
       "          [-0.1497,  0.1832,  0.0446, -0.1096,  0.3211,  0.0588,  0.2840,  0.0145]],\n",
       "         requires_grad=True)),\n",
       " ('0.block 1.2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0287, -0.3111,  0.2709,  0.2738], requires_grad=True)),\n",
       " ('0.block 2.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.4255, -0.0864,  0.1882,  0.1863],\n",
       "          [-0.4008, -0.3108,  0.1785, -0.3517],\n",
       "          [ 0.0357,  0.2770,  0.3382, -0.1390],\n",
       "          [-0.2045, -0.2981,  0.3186,  0.0082],\n",
       "          [ 0.1344, -0.3646, -0.2307, -0.1557],\n",
       "          [-0.1442, -0.3215, -0.0018,  0.0150],\n",
       "          [ 0.0429, -0.4228, -0.3592, -0.4350],\n",
       "          [-0.0234, -0.1675,  0.3142,  0.4252]], requires_grad=True)),\n",
       " ('0.block 2.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0946, -0.4122, -0.1647,  0.0125,  0.1349,  0.3734,  0.2601, -0.4761],\n",
       "         requires_grad=True)),\n",
       " ('0.block 2.2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2631, -0.0529,  0.3478,  0.1046, -0.0911,  0.0611,  0.1771, -0.1259],\n",
       "          [-0.0919, -0.1058,  0.0144, -0.3219,  0.3299,  0.0216,  0.3405, -0.2728],\n",
       "          [ 0.0200, -0.0285,  0.1204,  0.3019,  0.1800, -0.2411, -0.0659,  0.2762],\n",
       "          [ 0.3309, -0.2793, -0.1787,  0.0435,  0.1180,  0.1534, -0.1427,  0.2743]],\n",
       "         requires_grad=True)),\n",
       " ('0.block 2.2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0398, -0.3216, -0.3134, -0.2581], requires_grad=True)),\n",
       " ('0.block 3.0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2478, -0.2677,  0.3885, -0.0945],\n",
       "          [-0.2814,  0.1416, -0.4042, -0.3762],\n",
       "          [-0.0606, -0.3802, -0.4579, -0.3401],\n",
       "          [ 0.3409,  0.4572, -0.4535, -0.4857],\n",
       "          [-0.4982,  0.1581,  0.0941, -0.3589],\n",
       "          [ 0.0631,  0.4907, -0.2783, -0.0049],\n",
       "          [ 0.4926, -0.0385, -0.4661, -0.2626],\n",
       "          [-0.3028,  0.4018, -0.3818,  0.4745]], requires_grad=True)),\n",
       " ('0.block 3.0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.4138,  0.0692, -0.0087,  0.4949, -0.0737, -0.1594, -0.4514,  0.3622],\n",
       "         requires_grad=True)),\n",
       " ('0.block 3.2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2652, -0.1255, -0.2363,  0.1145,  0.2495, -0.3108, -0.2754, -0.1921],\n",
       "          [ 0.0964,  0.0916, -0.1314, -0.1001,  0.2968,  0.3531, -0.0374,  0.1913],\n",
       "          [ 0.1932, -0.0911,  0.3354,  0.2227,  0.1087, -0.3173,  0.1420,  0.2347],\n",
       "          [-0.1159,  0.1774,  0.1746,  0.0486,  0.0886, -0.1082,  0.0569, -0.2933]],\n",
       "         requires_grad=True)),\n",
       " ('0.block 3.2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0043,  0.1732, -0.0434, -0.0368], requires_grad=True)),\n",
       " ('1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2308,  0.1393, -0.4095,  0.4671]], requires_grad=True)),\n",
       " ('1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.2202], requires_grad=True)),\n",
       " ('fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0160]], requires_grad=True)),\n",
       " ('fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.7373], requires_grad=True))]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rgnet.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13faef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## <parameters()>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce39dc65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.1639,  0.2251, -0.4275, -0.4276],\n",
       "         [-0.1055,  0.1964, -0.2566, -0.3146],\n",
       "         [-0.0649,  0.1358, -0.2405, -0.4776],\n",
       "         [-0.2704, -0.0756, -0.1673,  0.4028],\n",
       "         [-0.1686,  0.3300,  0.0248,  0.0440],\n",
       "         [-0.0455, -0.0727,  0.1271,  0.0872],\n",
       "         [-0.3912, -0.1992,  0.0052, -0.0626],\n",
       "         [-0.1598,  0.0920, -0.2388, -0.4927]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.3822,  0.1829,  0.0156, -0.1684,  0.0761,  0.1758, -0.0640, -0.4413],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 2.9448e-04, -1.2497e-01, -2.6117e-01,  3.0121e-01, -2.4586e-01,\n",
       "           1.1525e-01,  1.1274e-01, -2.8943e-01],\n",
       "         [ 6.0678e-05, -3.0486e-01, -1.8523e-01,  1.7244e-01, -8.3854e-02,\n",
       "          -2.0622e-01, -1.7788e-01,  1.3064e-01],\n",
       "         [ 6.0024e-02,  3.1581e-01,  2.8538e-02,  2.4565e-02, -3.3780e-01,\n",
       "          -3.0268e-01,  2.7581e-01, -3.2305e-01],\n",
       "         [ 3.1388e-01, -2.5387e-01,  1.0965e-01,  2.5348e-01, -3.2901e-01,\n",
       "          -3.3791e-01,  3.5155e-01, -3.3635e-01]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.3401,  0.3132, -0.3024,  0.2860], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1336, -0.1995,  0.2449,  0.4198],\n",
       "         [-0.0728, -0.4344, -0.3410, -0.4169],\n",
       "         [-0.3948,  0.3852,  0.0481, -0.1646],\n",
       "         [-0.3447,  0.0292, -0.0877,  0.2629],\n",
       "         [ 0.3083, -0.1924,  0.4442, -0.1529],\n",
       "         [-0.3885, -0.1417,  0.3478,  0.1737],\n",
       "         [-0.1381, -0.2959,  0.2470, -0.4145],\n",
       "         [-0.1498, -0.3662,  0.3438,  0.3000]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.3766, -0.0611, -0.4432, -0.4459, -0.0248, -0.1326, -0.4823, -0.4727],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.1238,  0.1168, -0.2286,  0.0250, -0.0698,  0.2412, -0.2949,  0.1938],\n",
       "         [ 0.1587, -0.1360,  0.1145, -0.2914,  0.0062, -0.2508,  0.0323,  0.0420],\n",
       "         [-0.1957,  0.1594, -0.2187,  0.3246,  0.0606, -0.3478, -0.0421,  0.0562],\n",
       "         [-0.1497,  0.1832,  0.0446, -0.1096,  0.3211,  0.0588,  0.2840,  0.0145]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0287, -0.3111,  0.2709,  0.2738], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.4255, -0.0864,  0.1882,  0.1863],\n",
       "         [-0.4008, -0.3108,  0.1785, -0.3517],\n",
       "         [ 0.0357,  0.2770,  0.3382, -0.1390],\n",
       "         [-0.2045, -0.2981,  0.3186,  0.0082],\n",
       "         [ 0.1344, -0.3646, -0.2307, -0.1557],\n",
       "         [-0.1442, -0.3215, -0.0018,  0.0150],\n",
       "         [ 0.0429, -0.4228, -0.3592, -0.4350],\n",
       "         [-0.0234, -0.1675,  0.3142,  0.4252]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0946, -0.4122, -0.1647,  0.0125,  0.1349,  0.3734,  0.2601, -0.4761],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2631, -0.0529,  0.3478,  0.1046, -0.0911,  0.0611,  0.1771, -0.1259],\n",
       "         [-0.0919, -0.1058,  0.0144, -0.3219,  0.3299,  0.0216,  0.3405, -0.2728],\n",
       "         [ 0.0200, -0.0285,  0.1204,  0.3019,  0.1800, -0.2411, -0.0659,  0.2762],\n",
       "         [ 0.3309, -0.2793, -0.1787,  0.0435,  0.1180,  0.1534, -0.1427,  0.2743]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0398, -0.3216, -0.3134, -0.2581], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2478, -0.2677,  0.3885, -0.0945],\n",
       "         [-0.2814,  0.1416, -0.4042, -0.3762],\n",
       "         [-0.0606, -0.3802, -0.4579, -0.3401],\n",
       "         [ 0.3409,  0.4572, -0.4535, -0.4857],\n",
       "         [-0.4982,  0.1581,  0.0941, -0.3589],\n",
       "         [ 0.0631,  0.4907, -0.2783, -0.0049],\n",
       "         [ 0.4926, -0.0385, -0.4661, -0.2626],\n",
       "         [-0.3028,  0.4018, -0.3818,  0.4745]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4138,  0.0692, -0.0087,  0.4949, -0.0737, -0.1594, -0.4514,  0.3622],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.2652, -0.1255, -0.2363,  0.1145,  0.2495, -0.3108, -0.2754, -0.1921],\n",
       "         [ 0.0964,  0.0916, -0.1314, -0.1001,  0.2968,  0.3531, -0.0374,  0.1913],\n",
       "         [ 0.1932, -0.0911,  0.3354,  0.2227,  0.1087, -0.3173,  0.1420,  0.2347],\n",
       "         [-0.1159,  0.1774,  0.1746,  0.0486,  0.0886, -0.1082,  0.0569, -0.2933]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0043,  0.1732, -0.0434, -0.0368], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.2308,  0.1393, -0.4095,  0.4671]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2202], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0160]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.7373], requires_grad=True)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rgnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12f648d2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',\n",
       "  Sequential(\n",
       "    (block 0): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (block 1): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (block 2): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (block 3): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )),\n",
       " ('1', Linear(in_features=4, out_features=1, bias=True)),\n",
       " ('fc', Linear(in_features=1, out_features=1, bias=True))]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rgnet.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3f8c8053",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (block 0): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (block 1): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (block 2): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (block 3): Sequential(\n",
       "     (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       " ),\n",
       " Linear(in_features=4, out_features=1, bias=True),\n",
       " Linear(in_features=1, out_features=1, bias=True)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rgnet.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "65fdf821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3766, -0.0611, -0.4432, -0.4459, -0.0248, -0.1326, -0.4823, -0.4727])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet[0][1][0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "818b70aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3766, -0.0611, -0.4432, -0.4459, -0.0248, -0.1326, -0.4823, -0.4727])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet.state_dict()['0.block 1.0.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "667c17e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0186],\n",
       "        [-0.0186]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "08bdf86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "419309a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0.block 2.1', ReLU())\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-1f520eb2f565>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrgnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kradk\\anaconda3\\envs\\d2l\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m             )\n\u001b[1;32m--> 848\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    849\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kradk\\anaconda3\\envs\\d2l\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 892\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    893\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "list(rgnet2.named_modules())\n",
    "\n",
    "for mod in rgnet.named_modules():\n",
    "    print(mod)\n",
    "    input()\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0c0840",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgnet2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a84864",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1 -> 2 -> 3 -> 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fe137716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (first): Sequential(\n",
       "    (0): Sequential(\n",
       "      (block_2 0): Sequential(\n",
       "        (block 0): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (block 1): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (block 2): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (block 3): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (block_2 1): Sequential(\n",
       "        (block 0): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (block 1): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (block 2): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (block 3): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (block_2 2): Sequential(\n",
       "        (block 0): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (block 1): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (block 2): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (block 3): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (block_2 3): Sequential(\n",
       "        (block 0): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (block 1): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (block 2): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "        (block 3): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Linear(in_features=4, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet3 = nn.Module()\n",
    "rgnet3.add_module('first', rgnet2)\n",
    "rgnet3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c791e",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d841411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## weights are initialized with kaiming uniform by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "efb4f1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "17a57e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0040, -0.0066,  0.0019, -0.0078]), tensor(0.))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "net.apply(init_normal)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67f2730f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1.]), tensor(0.))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_constant(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "net.apply(init_constant)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7104bc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0836, -0.3756,  0.3619,  0.3465])\n",
      "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
     ]
    }
   ],
   "source": [
    "def xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "def init_42(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 42)\n",
    "\n",
    "net[0].apply(xavier)\n",
    "net[2].apply(init_42)\n",
    "print(net[0].weight.data[0])\n",
    "print(net[2].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983dae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "U(5,10)   with probability 1/4\n",
    "0         with probability 1/2\n",
    "U(−10,−5) with probability 1/4\n",
    "\"\"\"\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "21b2dda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init weight torch.Size([8, 4])\n",
      "Init weight torch.Size([1, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.0000, -9.3964, -8.0282],\n",
       "        [-9.0053,  0.0000, -0.0000, -7.8644]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        print(\n",
    "            \"Init\",\n",
    "            *[(name, param.shape) for name, param in m.named_parameters()][0])\n",
    "        nn.init.uniform_(m.weight, -10, 10)\n",
    "        m.weight.data *= m.weight.data.abs() >= 5\n",
    "\n",
    "net.apply(my_init)\n",
    "net[0].weight[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37766d4",
   "metadata": {},
   "source": [
    "## Tied Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4a637958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "shared = nn.Linear(8, 8)\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), shared, nn.ReLU(), shared,\n",
    "                    nn.ReLU(), nn.Linear(8, 1))\n",
    "net(X)\n",
    "# Check whether the parameters are the same\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "net[2].weight.data[0, 0] = 100\n",
    "# Make sure that they are actually the same object rather than just having the\n",
    "# same value\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e9ee9",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "01f48e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c08d34f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b077c691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "786f1286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv1',\n",
       "  Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)),\n",
       " ('bn1',\n",
       "  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('relu', ReLU(inplace=True)),\n",
       " ('maxpool',\n",
       "  MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)),\n",
       " ('layer1',\n",
       "  Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )),\n",
       " ('layer2',\n",
       "  Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )),\n",
       " ('layer3',\n",
       "  Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )),\n",
       " ('layer4',\n",
       "  Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )),\n",
       " ('avgpool', AdaptiveAvgPool2d(output_size=(1, 1))),\n",
       " ('fc', Linear(in_features=512, out_features=1000, bias=True))]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1dc14ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (9): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Rough way\n",
    "\n",
    "module_list = list(model.children())\n",
    "final = module_list[-1]\n",
    "in_feats = final.in_features\n",
    "in_feats\n",
    "\n",
    "new_model = nn.Sequential(*module_list[:-1],nn.Linear(in_feats, 10, bias=True))\n",
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b2a45933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (9): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Rough way\n",
    "\n",
    "module_list = list(model.children())\n",
    "final = module_list[-1]\n",
    "initial = module_list[0]\n",
    "new_initial = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "new_initial.weight.data = initial.weight.data.mean(-3)\n",
    "\n",
    "module_list[0] = new_initial\n",
    "\n",
    "in_feats = final.in_features\n",
    "in_feats\n",
    "\n",
    "new_model = nn.Sequential(*module_list[:-1],nn.Linear(in_feats, 10, bias=True))\n",
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddac82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaiming He "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147a8405",
   "metadata": {},
   "source": [
    "## File I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6327936",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Anything serializable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2f477c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')\n",
    "\n",
    "x2 = torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "17707dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y], 'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2e751792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5519e410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cafbea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y  = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "01252b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'mlp_params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ff8266ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=8, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=8, out_features=8, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), shared, nn.ReLU(), shared,\n",
    "                    nn.ReLU(), nn.Linear(8, 1))\n",
    "clone.load_state_dict(torch.load('mlp_params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bfdd9df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True],\n",
       "        [True]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8444070",
   "metadata": {},
   "source": [
    "## GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cb2ed94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun 13 18:36:57 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 462.31       Driver Version: 462.31       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce MX330      WDDM  | 00000000:02:00.0 Off |                  N/A |\n",
      "| N/A   64C    P0    N/A /  N/A |    471MiB /  2048MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      6324      C   ...onda3\\envs\\d2l\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "264f49ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'),\n",
       " <torch.cuda.device at 0x1f913f864c0>,\n",
       " <torch.cuda.device at 0x1f913f86ee0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cpu'), torch.cuda.device('cuda'), torch.cuda.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "32fe2534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "674609e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0),\n",
       " device(type='cpu'),\n",
       " [device(type='cuda', index=0)])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_gpu(i=0): \n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def try_all_gpus():  \n",
    "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\"\"\"\n",
    "    devices = [\n",
    "        torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "try_gpu(), try_gpu(10), try_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6e60c254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5d5751a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.to(torch.device('cuda'))\n",
    "# x = x.cuda()\n",
    "# x = x.cpu()\n",
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "701fefaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-2527552080a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "50075f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "228f023b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2,3, device=try_gpu(0))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7c5fa1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0')\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-ef7086464f52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "Z = x.cpu()\n",
    "print(x)\n",
    "print(Z)\n",
    "x+Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1dda493a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7b0c9e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(torch.device('cuda'))\n",
    "# net.cuda()\n",
    "net[0].weight.data.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1cb053",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "delta = 1e-3\n",
    "for epoch in range(epochs):\n",
    "    loss = \n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f7c8d5",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "698d5c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (9): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Rough way\n",
    "\n",
    "module_list = list(model.children())\n",
    "final = module_list[-1]\n",
    "initial = module_list[0]\n",
    "new_initial = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "new_initial.weight.data = initial.weight.data.mean(-3)\n",
    "\n",
    "module_list[0] = new_initial\n",
    "\n",
    "in_feats = final.in_features\n",
    "in_feats\n",
    "\n",
    "new_model = nn.Sequential(*module_list[:-1],nn.Linear(in_feats, 10, bias=True))\n",
    "new_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
